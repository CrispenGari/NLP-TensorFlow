{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01_Emotion_Prediction_From_Text.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYgcdF596ey_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVe7YIfn6ruW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT5TU5IL7PlG"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-Xgp5qZ6rsB"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import csv, json, time\n",
        "import pandas as pd"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_R85uaq9Lc1"
      },
      "source": [
        "### Mounting the google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yi9xrHhg9KjX",
        "outputId": "a373751a-47fc-425d-84f0-f1396f3d179d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9c5dvVn6rpl",
        "outputId": "2b457bdd-cf38-4256-dd00-958c03b683fb"
      },
      "source": [
        "data_path = '/content/drive/MyDrive/NLP Data/emotions-nlp'\n",
        "os.path.exists(data_path)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cowJr9Oy7wIN"
      },
      "source": [
        "### So here we have three files which are:\n",
        "1. test.txt\n",
        "2. train.txt\n",
        "3. val.txt\n",
        "\n",
        "And each of these file contains lines with a respective lable. The text in these files looks as follows:\n",
        "\n",
        "```txt\n",
        "im feeling quite sad and sorry for myself but ill snap out of it soon;sadness\n",
        "i feel like i am still looking at a blank canvas blank pieces of paper;sadness\n",
        "i feel like a faithful servant;love\n",
        "```\n",
        "\n",
        "### Data Procesing.\n",
        "\n",
        "I want to create csv files from these text files:\n",
        "1. train.csv\n",
        "2. test.csv\n",
        "3. validation.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyhNek3m6rnM"
      },
      "source": [
        "with open(os.path.join(data_path, 'test.txt'), 'r') as reader:\n",
        "  test_data = reader.read().splitlines()\n",
        "\n",
        "with open(os.path.join(data_path, 'train.txt'), 'r') as reader:\n",
        "  train_data = reader.read().splitlines()\n",
        "\n",
        "with open(os.path.join(data_path, 'val.txt'), 'r') as reader:\n",
        "  valid_data = reader.read().splitlines()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwUh8xCy6rkk"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "def tabulate(column_names, data):\n",
        "  table = PrettyTable(column_names)\n",
        "  for row in data:\n",
        "    table.add_row(row)\n",
        "  print(table)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-drK2Kku-UFc"
      },
      "source": [
        "### Checking how many examples do we have for each set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Bpm82Yk6rh1",
        "outputId": "1268ba02-bbe5-4d22-ecdb-c2184fef09b9"
      },
      "source": [
        "column_names = [\"SET\", \"NUM EXAMPLE(S)\"]\n",
        "data_table = [\n",
        "  [\"TESTING\", len(test_data)],\n",
        "  [\"TRAINING\", len(train_data)],\n",
        "  [\"VALIDATING\", len(valid_data)],\n",
        "]\n",
        "tabulate(column_names, data_table)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------+----------------+\n",
            "|    SET     | NUM EXAMPLE(S) |\n",
            "+------------+----------------+\n",
            "|  TESTING   |      2000      |\n",
            "|  TRAINING  |     16000      |\n",
            "| VALIDATING |      2000      |\n",
            "+------------+----------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr6294bL-9Yk"
      },
      "source": [
        "### Creating Labels.\n",
        "Each line in these set contains a text and it's respective label superated by a seimicolon `;`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQalwuBh6re8",
        "outputId": "6610733d-a835-4702-d3dd-a9f545e0a4e6"
      },
      "source": [
        "test_data[0].split(';')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['im feeling rather rotten so im not very ambitious right now', 'sadness']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_0t5wAqAnMc"
      },
      "source": [
        "### A timer formater functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BtsIYnAZAwDO"
      },
      "source": [
        "def hms_string(sec_elapsed):\n",
        "    h = int(sec_elapsed / (60 * 60))\n",
        "    m = int((sec_elapsed % (60 * 60)) / 60)\n",
        "    s = sec_elapsed % 60\n",
        "    return \"{}:{:>02}:{:>05.2f}\".format(h, m, s)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVkLKZ0nAxjM"
      },
      "source": [
        "### A function that create csv files from list of data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqytvMVu_NGp",
        "outputId": "9a72ac5a-204b-4015-9d4e-eb08b7da5172"
      },
      "source": [
        "def create_csv_data(data_set, file_name):\n",
        "  start = time.time()\n",
        "  row_list = [\n",
        "      [\"text\", \"emotion\"]\n",
        "  ]\n",
        "  for line in data_set:\n",
        "    text_emotion = line.split(';')\n",
        "    row_list.append(text_emotion)\n",
        "  \n",
        "  with open(os.path.join(data_path, file_name), 'w', newline='') as file:\n",
        "      writer = csv.writer(file)\n",
        "      writer.writerows(row_list)\n",
        "  print(\n",
        "    f\"Created file: {file_name},  ETA: {hms_string(time.time()- start)}\"\n",
        "  )\n",
        "\n",
        "\"\"\"\n",
        "CREATING CSV FILES FOR ALL THE SETS.\n",
        "\"\"\"\n",
        "\n",
        "create_csv_data(train_data, 'train.csv')\n",
        "create_csv_data(valid_data, 'valid.csv')\n",
        "create_csv_data(test_data, 'test.csv')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Created file: train.csv,  ETA: 0:00:00.07\n",
            "Created file: valid.csv,  ETA: 0:00:00.01\n",
            "Created file: test.csv,  ETA: 0:00:00.01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXo5RXchDYek"
      },
      "source": [
        "### Testing if we loaded the data corectly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TnuUCBkX_ysA",
        "outputId": "62dae239-aa5d-4f24-a5ec-e302b218592e"
      },
      "source": [
        "train_df = pd.read_csv(os.path.join(data_path, 'train.csv'))\n",
        "test_df = pd.read_csv(os.path.join(data_path, 'test.csv'))\n",
        "valid_df = pd.read_csv(os.path.join(data_path, 'valid.csv'))\n",
        "train_df.emotion.unique(), test_df.emotion.unique(), valid_df.emotion.unique()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['sadness', 'anger', 'love', 'surprise', 'fear', 'joy'],\n",
              "       dtype=object),\n",
              " array(['sadness', 'joy', 'fear', 'anger', 'love', 'surprise'],\n",
              "       dtype=object),\n",
              " array(['sadness', 'love', 'anger', 'joy', 'fear', 'surprise'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJUR60XoDce9"
      },
      "source": [
        "So as we can see that we have `6` emotions. What are we going to do next.\n",
        "\n",
        "### Preparing data for the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apJgE9UyC_ti"
      },
      "source": [
        "X_train_values = train_df.text.values\n",
        "y_train_values = train_df.emotion.values\n",
        "\n",
        "X_valid_values = valid_df.text.values\n",
        "y_valid_values = valid_df.emotion.values\n",
        "\n",
        "X_test_values = test_df.text.values\n",
        "y_test_values = test_df.emotion.values\n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpfoLHb_GERl"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfTSYjOZFLe_"
      },
      "source": [
        "### We want to preprocess the labels first\n",
        "* Convert them to digits\n",
        "```\n",
        "['anger', 'fear', 'joy', 'love', 'sadness', 'surprise' ]\n",
        "[0, 1, 2, 3, 4, 5]\n",
        "```\n",
        "* For the label encoding we are going to use the `skit-learn` `LabelEncoder()` class.\n",
        "\n",
        "* We `one_hot_encode` them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0-RSTMlC_nn",
        "outputId": "eae27070-3f59-4590-ce71-6f8632c8f1eb"
      },
      "source": [
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train_values)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGuznEjHC_ke"
      },
      "source": [
        "y_train_labels = encoder.transform(y_train_values)\n",
        "y_test_labels = encoder.transform(y_test_values)\n",
        "y_valid_label = encoder.transform(y_valid_values)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rU2QTZeHk6d"
      },
      "source": [
        "### Now we can convert our labels to `one_hot` encoded vectors. \n",
        "There are a lot of ways of doing this we can use:\n",
        "\n",
        "1. `tf.one_hot()`\n",
        "2. sklearn `OneHotEncoder()` class.\n",
        "3. numpy `eye()` function.\n",
        "\n",
        "We are going to use numpy `eye()` function.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NnY-LI_IZPV",
        "outputId": "3fd88348-3888-4cf7-f5b2-5228df487981"
      },
      "source": [
        "def one_hot_encode(index, depth=6):\n",
        "  return np.eye(depth)[index]\n",
        "one_hot_encode(3)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 1., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQgdo0XjC_ht"
      },
      "source": [
        "y_train_labels_one_hot = np.array(list(map(one_hot_encode, y_train_labels ))).astype('float32')\n",
        "y_test_labels_one_hot = np.array(list(map(one_hot_encode, y_test_labels ))).astype('float32')\n",
        "y_valid_labels_one_hot = np.array(list(map(one_hot_encode, y_valid_label ))).astype('float32')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NAlF4iwC_gG"
      },
      "source": [
        "### Processing the text (features).\n",
        "* Create a word vocabulary.\n",
        "* Create `stoi` from each sentence.\n",
        "* pad the sentences so that they will have the same size.\n",
        "\n",
        "* We are going to join the `train` and `validation` features and labels, and then we will split them during training.\n",
        "\n",
        "**We are not going to torch the test data.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rt06MXhP5Oc",
        "outputId": "1992f840-c04f-4328-ec76-690d01ecab50"
      },
      "source": [
        "features = np.concatenate([X_train_values, X_valid_values])\n",
        "labels = np.concatenate([y_train_labels_one_hot, y_valid_labels_one_hot])\n",
        "features.shape, labels.shape"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((18000,), (18000, 6))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "615YPxEWC_b8"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ve0gN3_VC_Zj",
        "outputId": "ebc975d8-b45c-4497-cc0a-15d3dfbedb5b"
      },
      "source": [
        "counter = Counter()\n",
        "\n",
        "for sent in features:\n",
        "  words = word_tokenize(sent)\n",
        "  for word in words:\n",
        "    counter[word] += 1\n",
        "\n",
        "counter.most_common(9)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('i', 29044),\n",
              " ('feel', 12544),\n",
              " ('and', 10766),\n",
              " ('to', 10086),\n",
              " ('the', 9383),\n",
              " ('a', 6982),\n",
              " ('feeling', 5785),\n",
              " ('that', 5701),\n",
              " ('of', 5587)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4O30HxWOMKy"
      },
      "source": [
        "### Vocabulary size (aka) number of unique words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9sbL8tdC_Wd",
        "outputId": "2a40cc3e-7406-4ab2-dae3-d3f0f8350251"
      },
      "source": [
        "vocab_size = len(counter)\n",
        "print(f\"Vocabulary size: {vocab_size}\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 16194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAZQl6w2OhL0"
      },
      "source": [
        "### Creating word vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuPLINFdC_Ti"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKLNiFInC_QU"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=vocab_size)\n",
        "tokenizer.fit_on_texts(features)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aEBCExtqC_NM"
      },
      "source": [
        "word_indices = tokenizer.word_index\n",
        "word_indices_reversed = dict([(v, k) for (k, v) in word_indices.items()])"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IscmPgMpSFoM"
      },
      "source": [
        "### Helper functions.\n",
        "\n",
        "We are going to create two helper function. One will convert the text given to sequences and the other will take sequences and convert them to text.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em8lTdRm_ypM"
      },
      "source": [
        "def sequence_to_text(sequences):\n",
        "    return \" \".join(word_indices_reversed[i] for i in sequences)\n",
        "def text_to_sequence(sent):\n",
        "  words = word_tokenize(sent.lower())\n",
        "  sequences = []\n",
        "  for word in words:\n",
        "    try:\n",
        "      sequences.append(word_indices[word])\n",
        "    except:\n",
        "      sequences.append(0)\n",
        "  return sequences"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx8TgBAiTdLT"
      },
      "source": [
        "### Loading pretrainned weights glove.6B.\n",
        "We are going to load this pretrained weights from our google drive. I've uploaded them on my google drive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zek9CrB1TOBO"
      },
      "source": [
        "embedding_path = \"/content/drive/MyDrive/NLP Data/glove.6B/glove.6B.100d.txt\""
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6LrBcKsTcuL"
      },
      "source": [
        "embeddings_dictionary = dict()\n",
        "with open(embedding_path, encoding='utf8') as glove_file:\n",
        "    for line in glove_file:\n",
        "        records = line.split()\n",
        "        word  = records[0]\n",
        "        vectors = np.asarray(records[1:], dtype='float32')\n",
        "        embeddings_dictionary[word] = vectors"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5Vs2gHHUXOF"
      },
      "source": [
        "> Creating an `embedding matrix` that suits our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muB0PIgiTcr1"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    vector = embeddings_dictionary.get(word)\n",
        "    if vector is not None:\n",
        "      try:\n",
        "        embedding_matrix[index] = vector\n",
        "      except:\n",
        "        pass"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_My9Wf8WoUQ"
      },
      "source": [
        "### Creating sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFA_nBkTTcoM"
      },
      "source": [
        "sequence_tokens = tokenizer.texts_to_sequences(features)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yGvx2PZeTcjt",
        "outputId": "cae95bed-f727-43ed-93a1-11b06926be7a"
      },
      "source": [
        "sequence_to_text(sequence_tokens[0])"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'i didnt feel humiliated'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtB8FDOgW2Mv"
      },
      "source": [
        "### Padding sequences.\n",
        "We now want our sequences to have the same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHisHjeuV69a"
      },
      "source": [
        "max_words = 100\n",
        "tokens_sequence_padded = pad_sequences(sequence_tokens, maxlen=max_words, padding=\"post\", truncating=\"post\")"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lW_mPvD2XVCN"
      },
      "source": [
        "### Building the model.\n",
        "\n",
        "### Model achitecture.\n",
        "\n",
        "```\n",
        "                [ Embedding Layer]\n",
        "                        |\n",
        "                        |\n",
        "[ LSTM ] <---- [Bidirectional Layer] ----> [GRU] (forward_layer)\n",
        " (backward_layer)       |\n",
        "                        |\n",
        "        [  Gated Recurrent Unit  (GRU)  ]\n",
        "                        |\n",
        "                        |\n",
        "        [ Long Short Term Memory (LSTM) ]\n",
        "                        |\n",
        "                        |\n",
        "                [ Flatten Layer]\n",
        "                        |\n",
        "                        |\n",
        "                 [Dense Layer 1]\n",
        "                        |\n",
        "                        | \n",
        "                   [ Dropout ]\n",
        "                        |\n",
        "                        |   \n",
        "                 [Dense Layer 2]\n",
        "                        |\n",
        "                        |\n",
        "                 [Dense Layer 3] (output [6 classes])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2_IPav4XBUm",
        "outputId": "298251a0-a76d-467a-f4bc-950186273339"
      },
      "source": [
        "forward_layer = keras.layers.GRU(128, return_sequences=True, dropout=.25 )\n",
        "backward_layer = keras.layers.LSTM(128, activation='tanh', return_sequences=True,\n",
        "                       go_backwards=True, dropout=.25)\n",
        "input_layer = keras.layers.Input(shape=(100, ), name=\"input_layer\")\n",
        "\n",
        "embedding_layer = keras.layers.Embedding(\n",
        "      vocab_size, \n",
        "      100, \n",
        "      input_length=max_words,\n",
        "      weights=[embedding_matrix], \n",
        "      trainable=True,\n",
        "      name = \"embedding_layer\"\n",
        ")(input_layer)\n",
        "bidirectional_layer = keras.layers.Bidirectional(\n",
        "    forward_layer,\n",
        "    backward_layer = backward_layer,\n",
        "    name= \"bidirectional_layer\"\n",
        ")(embedding_layer)\n",
        "\n",
        "gru_layer = keras.layers.GRU(\n",
        "    512, return_sequences=True,\n",
        "   dropout=.5,\n",
        "    name= \"gru_layer\"\n",
        ")(bidirectional_layer)\n",
        "\n",
        "lstm_layer = keras.layers.LSTM(\n",
        "    512, return_sequences=True,\n",
        "   dropout=.5,\n",
        "    name=\"lstm_layer\"\n",
        ")(gru_layer)\n",
        "flatten_layer = keras.layers.Flatten(name=\"flatten_layer\")(lstm_layer)\n",
        "fc_1 = keras.layers.Dense(64, activation='relu', name=\"dense_1\")(flatten_layer)\n",
        "dropout_layer = keras.layers.Dropout(rate=0.5, name=\"dropout_layer\")(fc_1)\n",
        "fc_2 = keras.layers.Dense(512, activation='relu', name=\"dense_2\")(dropout_layer)\n",
        "output_layer = keras.layers.Dense(6, activation='softmax')(fc_2)\n",
        "emotion_model = keras.Model(inputs=input_layer, outputs=output_layer, name=\"emotional_model\")\n",
        "emotion_model.summary()"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"emotional_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 100)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_layer (Embedding)  (None, 100, 100)          1619400   \n",
            "_________________________________________________________________\n",
            "bidirectional_layer (Bidirec (None, 100, 256)          205568    \n",
            "_________________________________________________________________\n",
            "gru_layer (GRU)              (None, 100, 512)          1182720   \n",
            "_________________________________________________________________\n",
            "lstm_layer (LSTM)            (None, 100, 512)          2099200   \n",
            "_________________________________________________________________\n",
            "flatten_layer (Flatten)      (None, 51200)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                3276864   \n",
            "_________________________________________________________________\n",
            "dropout_layer (Dropout)      (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               33280     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 6)                 3078      \n",
            "=================================================================\n",
            "Total params: 8,420,110\n",
            "Trainable params: 8,420,110\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8E_tEILobB-l"
      },
      "source": [
        "### Compiling and training the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VaKv9tObB2I"
      },
      "source": [
        "early_stoping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto',\n",
        "    baseline=None,\n",
        "    restore_best_weights=False,\n",
        ")\n",
        "\n",
        "emotion_model.compile(\n",
        "    loss = keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    optimizer = keras.optimizers.Adam(1e-3, 0.5),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fH8T6U0ibBxi",
        "outputId": "edeb6816-b1f0-4440-e304-56996e061c81"
      },
      "source": [
        "emotion_model.fit(\n",
        "    tokens_sequence_padded,\n",
        "    labels,\n",
        "    epochs = 10,\n",
        "    verbose = 1,\n",
        "    validation_split = .2,\n",
        "    shuffle=True,\n",
        "    batch_size= 32,\n",
        "    validation_batch_size = 16,\n",
        "    callbacks = [early_stoping]\n",
        ")"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "450/450 [==============================] - 35s 69ms/step - loss: 1.3407 - accuracy: 0.4952 - val_loss: 0.7442 - val_accuracy: 0.7078\n",
            "Epoch 2/10\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.6022 - accuracy: 0.7803 - val_loss: 0.2689 - val_accuracy: 0.9036\n",
            "Epoch 3/10\n",
            "450/450 [==============================] - 30s 67ms/step - loss: 0.3025 - accuracy: 0.8947 - val_loss: 0.1739 - val_accuracy: 0.9347\n",
            "Epoch 4/10\n",
            "450/450 [==============================] - 30s 67ms/step - loss: 0.2058 - accuracy: 0.9203 - val_loss: 0.1600 - val_accuracy: 0.9353\n",
            "Epoch 5/10\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.1622 - accuracy: 0.9328 - val_loss: 0.1485 - val_accuracy: 0.9347\n",
            "Epoch 6/10\n",
            "450/450 [==============================] - 30s 67ms/step - loss: 0.1471 - accuracy: 0.9373 - val_loss: 0.1460 - val_accuracy: 0.9281\n",
            "Epoch 7/10\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.1420 - accuracy: 0.9442 - val_loss: 0.1387 - val_accuracy: 0.9394\n",
            "Epoch 8/10\n",
            "450/450 [==============================] - 30s 67ms/step - loss: 0.1298 - accuracy: 0.9451 - val_loss: 0.1437 - val_accuracy: 0.9353\n",
            "Epoch 9/10\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.1087 - accuracy: 0.9513 - val_loss: 0.1506 - val_accuracy: 0.9350\n",
            "Epoch 10/10\n",
            "450/450 [==============================] - 28s 62ms/step - loss: 0.0964 - accuracy: 0.9560 - val_loss: 0.1541 - val_accuracy: 0.9411\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe3743ee6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji7Jjeuafxov"
      },
      "source": [
        "### Evaluating the model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVJCnBxRf0VL",
        "outputId": "1a946def-b66a-458a-d339-c1eb38385091"
      },
      "source": [
        "def text_to_padded_sequences(sent):\n",
        "  tokens = text_to_sequence(sent)\n",
        "  padded_tokens = pad_sequences([tokens], maxlen=max_words, padding=\"post\", truncating=\"post\")\n",
        "  return tf.squeeze(padded_tokens)\n",
        "\n",
        "X_test = np.array(list(map(text_to_padded_sequences, X_test_values)))\n",
        "emotion_model.evaluate(X_test, y_test_labels_one_hot, verbose=1, batch_size=32)\n"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "63/63 [==============================] - 2s 20ms/step - loss: 0.1375 - accuracy: 0.9335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13748641312122345, 0.9334999918937683]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JGdHvW1cCB1"
      },
      "source": [
        "### Inference."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfTD8ynWbBuX"
      },
      "source": [
        "def predict(model, sent):\n",
        "    classes = ['anger', 'fear', 'joy', 'love', 'sadness', 'surprise' ]\n",
        "    tokens = text_to_sequence(sent)\n",
        "    padded_tokens = pad_sequences([tokens], maxlen=max_words, padding=\"post\", truncating=\"post\")\n",
        "    prediction = tf.argmax(model.predict(padded_tokens), axis=1).numpy()[0]\n",
        "    class_name = classes[prediction]\n",
        "    print(f'Predicted Class:\\t {prediction}\\nPredicted Category:\\t{class_name}')"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMmn3HgchODO"
      },
      "source": [
        "### Sadness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "di_Xaqp0bBrf",
        "outputId": "753431d6-46f9-4f9f-d54e-13036677ad75"
      },
      "source": [
        "predict(emotion_model, \"im updating my blog because i feel shitty\")"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Class:\t 4\n",
            "Predicted Category:\tsadness\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDoKLPbrhShU"
      },
      "source": [
        "### Fear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWLTsgoWbBp5",
        "outputId": "c25a8909-012b-4af6-877d-80536c1e1edb"
      },
      "source": [
        "predict(emotion_model, \"i am feeling apprehensive about it but also wildly excited\")"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Class:\t 1\n",
            "Predicted Category:\tfear\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGmhhc2hhe2E"
      },
      "source": [
        "### Joy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROGMsOAkbBlW",
        "outputId": "b1d49e61-06b4-4d86-ced3-12ca8eb8daef"
      },
      "source": [
        "predict(emotion_model, \"i feel a little mellow today.\")"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Class:\t 2\n",
            "Predicted Category:\tjoy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldyKnuyCh81u"
      },
      "source": [
        "### Surprise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxiWcolKheke",
        "outputId": "4a493864-bac4-4807-a2e0-503d864302ec"
      },
      "source": [
        "predict(emotion_model, \"i feel shocked and sad at the fact that there are so many sick people.\")"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Class:\t 5\n",
            "Predicted Category:\tsurprise\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMRVPZckiDQH"
      },
      "source": [
        "### Love"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7ZR6hRybBiH",
        "outputId": "3e2fe941-8b62-491e-caa2-010cbe8afd83"
      },
      "source": [
        "predict(emotion_model, \"i want each of you to feel my gentle embrace.\")"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Class:\t 3\n",
            "Predicted Category:\tlove\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxLlCtn-iUPr"
      },
      "source": [
        "### Anger."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBL9swhHhpM1",
        "outputId": "9785fbf5-c1aa-4db3-976c-f1b0248131f3"
      },
      "source": [
        "predict(emotion_model, \"i feel like my irritable sensitive combination skin has finally met it s match.\")"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted Class:\t 0\n",
            "Predicted Category:\tanger\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE_obFubiRzg"
      },
      "source": [
        "### Saving the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abyb05jjixlW",
        "outputId": "6fac4ddf-e6d1-41b4-a7b3-435a5f39bbbb"
      },
      "source": [
        "emotion_model.save(os.path.join(data_path, \"emotional_model.h5\"))\n",
        "print(\"Model Saved!!\")"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Saved!!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}