{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "canadian-dating",
   "metadata": {},
   "source": [
    "### Sentiment alalysis.\n",
    "\n",
    "In this notebook we are going to perform a sentiment classification task, weather a review is positive or negative based on the Amazon data. We are going to use the file `Books_small_10000.json` which is located in the files folder.\n",
    "\n",
    "### `books_small_10000.json` structure.\n",
    "\n",
    "```json\n",
    "{\"reviewerID\": \"A1F2H80A1ZNN1N\", \"asin\": \"B00GDM3NQC\", \"reviewerName\": \"Connie Correll\", \"helpful\": [0, 0], \"reviewText\": \"I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with.\", \"overall\": 5.0, \"summary\": \"Can't stop reading!\", \"unixReviewTime\": 1390435200, \"reviewTime\": \"01 23, 2014\"}\n",
    "```\n",
    "\n",
    "We are going to say any `\"overall\"` that is less than 3 is considered negative otherwise positive review. Note that from the previous notebook we got a reasonable accuracy by using pretrained word embeddings. In this one we are going to do the same thing as well.\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "sweet-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "import json, re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-indonesia",
   "metadata": {},
   "source": [
    "### Data preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "electric-craps",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review:\n",
    "    def __init__(self, review, sentiment):\n",
    "        self.review = review\n",
    "        self.sentiment = sentiment\n",
    "    def differentiate(sentiment):\n",
    "        return 0 if sentiment < 3 else 1 # 1 pos and 0 neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "little-shipping",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'files/Books_small_10000.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-folder",
   "metadata": {},
   "source": [
    "### Creating preprocessing function that remove Numbers and double spacing in a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "composite-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(sent):\n",
    "    a = re.sub(r'\\d', ' ', sent)\n",
    "    b = re.sub(r'\\s+', ' ', a)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ordered-strand",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = []\n",
    "with open(path, 'r') as reader:\n",
    "    for line in reader:\n",
    "        json_data = json.loads(line)\n",
    "        reviews.append(Review(\n",
    "            clean_text(json_data[\"reviewText\"]),\n",
    "            Review.differentiate(json_data[\"overall\"])\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nonprofit-simon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I bought both boxed sets, books - . Really a great series! Start book three weeks ago and just finished book . Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved! Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page! These are books you won't be disappointed with.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0].review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "settled-faculty",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_text = [i.review for i in reviews]\n",
    "reviews_labels = [i.sentiment for i in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "exempt-uzbekistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 9356, 0: 644})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(reviews_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prompt-prime",
   "metadata": {},
   "source": [
    "### Vocabulary size `aka` number of unique words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "collective-windows",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for sent in reviews_text:\n",
    "    words = word_tokenize(sent)\n",
    "    for word in words:\n",
    "        counter[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "governing-planning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 49831), ('the', 44135), (',', 38643)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "friendly-ceramic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47300"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(counter)\n",
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-expert",
   "metadata": {},
   "source": [
    "> We have `~47k`unique words in our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-modeling",
   "metadata": {},
   "source": [
    "### Now, Creating word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "threaded-korea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "scenic-brain",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocabulary_size)\n",
    "tokenizer.fit_on_texts(reviews_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "steady-portugal",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indices = tokenizer.word_index\n",
    "word_indices_reversed = dict([(v, k) for (k, v) in word_indices.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-liquid",
   "metadata": {},
   "source": [
    "### A function that converts `sequences to sents`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adaptive-video",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_text(seq):\n",
    "    return \" \".join([word_indices_reversed[i] for i in seq])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offensive-birthday",
   "metadata": {},
   "source": [
    "### A function that converts `sents to sequences`.\n",
    "We are going to use this function during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "brazilian-candle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_sequence(sent):\n",
    "    words = word_tokenize(str(sent).lower())\n",
    "    sequences = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            sequences.append(word_indices[word])\n",
    "        except:\n",
    "            sequences.append(0)\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-philadelphia",
   "metadata": {},
   "source": [
    "### Loading pretrainned weights `glove.6B.`\n",
    "We are going to use this weights in our `embedding` layer which is the first layer in the net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "outside-casino",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "with open(r\"C:\\Users\\crisp\\Downloads\\glove.6B\\glove.6B.100d.txt\", encoding='utf8') as glove_file:\n",
    "    for line in glove_file:\n",
    "        records = line.split()\n",
    "        word  = records[0]\n",
    "        vectors = np.asarray(records[1:], dtype='float32')\n",
    "        embeddings_dictionary[word] = vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-domestic",
   "metadata": {},
   "source": [
    "> Creating an `embedding` matrix that suits our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "corresponding-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    vector = embeddings_dictionary.get(word)\n",
    "    if vector is not None:\n",
    "        embedding_matrix[index] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-transfer",
   "metadata": {},
   "source": [
    "### Creating sequences from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "further-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_tokens = tokenizer.texts_to_sequences(reviews_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "extensive-haiti",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 477, 155, 6886, 1401, 57, 54, 4, 60, 55, 224, 11, 271, 958, 545, 2, 45, 346, 11, 11377, 6887, 7, 4, 60, 126, 2, 128, 290, 3, 378, 17, 113, 155, 1796, 77, 2, 17, 6307, 77, 325, 4, 209, 49, 580, 322, 1926, 233, 28, 181, 9, 998, 6, 1, 209, 48, 26, 397, 2, 372, 12, 179, 29, 1037, 230, 1, 229, 227, 106, 26, 57, 18, 357, 28, 431, 15]\n"
     ]
    }
   ],
   "source": [
    "print(sequence_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "expressed-creature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i bought both boxed sets books really a great series start book three weeks ago and just finished book sloane monroe is a great character and being able to follow her through both private life and her pi life gets a reader very involved although clues may be right in front of the reader there are twists and turns that keep one guessing until the last page these are books you won't be disappointed with\""
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_to_text(sequence_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sustained-setup",
   "metadata": {},
   "source": [
    "### Padding sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "moral-virginia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "finished-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 100\n",
    "sequences_padded = pad_sequences(sequence_tokens, maxlen=max_words, padding=\"post\", truncating=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-sucking",
   "metadata": {},
   "source": [
    "### Creating a model.\n",
    "\n",
    "### Model `Achitecture`\n",
    "\n",
    "```\n",
    "                [ Embedding Layer]\n",
    "                        |\n",
    "                        |\n",
    "[ LSTM ] <---- [Bidirectional Layer] ----> [GRU] (forward_layer)\n",
    " (backward_layer)       |\n",
    "                        |\n",
    "                 [ Flatten Layer]\n",
    "                        |\n",
    "                        |\n",
    "                 [Dense Layer 1]\n",
    "                        |\n",
    "                        |    \n",
    "                 [Dense Layer 2]\n",
    "                        |\n",
    "                        |\n",
    "                 [Dense Layer 3] (output [binary class])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "continuing-bankruptcy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"amazon_sentiment_classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_7 (Embedding)      (None, 100, 100)          4730000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 128)          74112     \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 64)                819264    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 512)               33280     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 5,657,169\n",
      "Trainable params: 927,169\n",
      "Non-trainable params: 4,730,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "forward_layer = keras.layers.GRU(64, return_sequences=True, dropout=.5 )\n",
    "backward_layer = keras.layers.LSTM(64, activation='relu', return_sequences=True,\n",
    "                       go_backwards=True, dropout=.5)\n",
    "\n",
    "# forward_layer = keras.layers.GRU(64, return_sequences=True, )\n",
    "# backward_layer = keras.layers.LSTM(64, activation='relu', return_sequences=True,\n",
    "#                        go_backwards=True)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(\n",
    "        vocabulary_size, 100, input_length=max_words, weights=[embedding_matrix], trainable=False\n",
    "    ),\n",
    "    keras.layers.Bidirectional(\n",
    "        forward_layer,\n",
    "        backward_layer = backward_layer\n",
    "    ),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(.3),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "    \n",
    "], name=\"amazon_sentiment_classifier\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "latter-advertising",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stoping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "fluid-substance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9500, 100), (9500,), (500, 100))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(np.array(sequences_padded), np.array(reviews_labels).astype('float32'), random_state=42, test_size = .05)\n",
    "X_train.shape, y_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-sheffield",
   "metadata": {},
   "source": [
    "### Trainning the Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "sophisticated-migration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "238/238 [==============================] - 35s 115ms/step - loss: 0.3002 - accuracy: 0.9165 - val_loss: 0.2162 - val_accuracy: 0.9274\n",
      "Epoch 2/10\n",
      "238/238 [==============================] - 25s 107ms/step - loss: 0.1781 - accuracy: 0.9372 - val_loss: 0.1990 - val_accuracy: 0.9289\n",
      "Epoch 3/10\n",
      "238/238 [==============================] - 26s 108ms/step - loss: 0.1457 - accuracy: 0.9425 - val_loss: 0.2344 - val_accuracy: 0.9268\n",
      "Epoch 4/10\n",
      "238/238 [==============================] - 26s 110ms/step - loss: 0.0960 - accuracy: 0.9603 - val_loss: 0.2595 - val_accuracy: 0.9274\n",
      "Epoch 5/10\n",
      "238/238 [==============================] - 27s 112ms/step - loss: 0.0578 - accuracy: 0.9769 - val_loss: 3.2454 - val_accuracy: 0.9095\n",
      "Epoch 00005: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = keras.optimizers.Adam()\n",
    ")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs = 10,\n",
    "    verbose = 1,\n",
    "    validation_split = .2,\n",
    "    shuffle=True,\n",
    "    batch_size= 32,\n",
    "    validation_batch_size = 16,\n",
    "    callbacks = [early_stoping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-teach",
   "metadata": {},
   "source": [
    "### Evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "juvenile-projector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 119ms/step - loss: 0.2797 - accuracy: 0.9240\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27966317534446716, 0.9240000247955322]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test, verbose=1, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "systematic-collectible",
   "metadata": {},
   "source": [
    "### Inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "consecutive-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sent):\n",
    "    class_names = [\"NEGATIVE\", \"POSITIVE\"]\n",
    "    tokens = sent_to_sequence(sent)\n",
    "    padded_tokens = pad_sequences([tokens], maxlen=max_words, padding=\"post\", truncating=\"post\")\n",
    "    prediction = tf.squeeze(tf.round(model(padded_tokens)).numpy().astype('int32'))\n",
    "    print(f'Predicted Class:\\t {prediction}\\nPredicted Category:\\t{class_names[prediction]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "right-brain",
   "metadata": {},
   "source": [
    "### Negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "hidden-guyana",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class:\t 0\n",
      "Predicted Category:\tNEGATIVE\n"
     ]
    }
   ],
   "source": [
    "predict(\"This book is very bad i dont like this kind of content.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadly-despite",
   "metadata": {},
   "source": [
    "### Positive Review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "minute-identifier",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class:\t 1\n",
      "Predicted Category:\tPOSITIVE\n"
     ]
    }
   ],
   "source": [
    "predict(\"This book is one of the amaizing books ever.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
